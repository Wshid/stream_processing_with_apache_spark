# [CHAP.12] 이벤트 시간 기반 스트림 처리
- **이벤트 시간 처리**(event-time processing)는
  - 이벤트가 생성된 타임라인에서
    - **이벤트 스트림**을 보고
  - 해당 관점에서 **처리 로직**을 적용하는 것을 말함
- 시간이 지남에 따라 이벤트 데이터의 **패턴**을 분석하는데 관심이 있는 경우
  - **이벤트가 생성**될 때 이벤트를 관찰하는 것처럼
  - 이벤트를 처리해야 함
- 이를 위해서는,
  - 이벤트 생성 시 **장치** 또는 **시스템**이
  - 이벤트를 `stamp` 해야 함
  - 일반적인 `timestamp`는 특정 **이벤트 바인딩 시간**을 나타냄
- 이벤트가 처리되는 순서가 아닌
  - **이벤트가 생성된 상대 순서**에 관심


## 12.1. 구조적 스트리밍에서의 이벤트 시간에 대한 이해
- 서버 측면에서 시간의 개념은
  - 주어진 **어플리케이션**을 실행하는 컴퓨터의 **내부 시계**에 의해 결정
- 머신 클러스터에서 실행되는 분산 어플리케이션의 경우
  - **네트워크 시간 프로토콜**(NTP, Network Time Protocol)과 같은
  - **클럭 동기화 및 프로토콜**을 사용하여
    - 모든 클럭을 동일한 시간에 맞추는 것이 필수적
- 컴퓨터 클러스터에서 실행되는 분산 어플리케이션의 여러 부분이
  - **이벤트**의 타임라인 및 **상대적 순서**에 대해 일관된 결정을 내릴 수 있도록 하기 위한 것
- 하지만 `센서 네트워크, 다른 데이터센터, 휴대전화`등과 같은 외부 장치에서 데이터를 가져올 때,
  - 예컨데 시계가 **머신 클러스터**와 일치한다고 보장할 수 없음
  - 시스템 내부 시계가 아닌
    - **생산 시스템**의 관점에서 들어오는 **이벤트**의 타임라인을 해석해야 함
- 이벤트 타임 라인 예시
  - x축을 처리시간
  - y축을 이벤트 타임라인의 내부 표현
  - `처리시간 != 이벤트시간`
- 이벤트가 시스템에 도착하면 **내부 시간** 개념이 진행
  - 첫번째 이벤트 00:08
    - 기계 시점에서 00:07 유입
    - 내부 시계 계산은, 이벤트 타임라인 인식에 영향을 미치지 않음
  - 이벤트 타임라인이 `00:08`로 진행
  - 다음 이벤트 배치인 `00:10, 00:12, 00:18` 도착
    - 이벤트 타임라인은 가장 최대 시간이므로, `00:18`로 결정
  - `00:15`가 유입, 이벤트 타임라인은 `00:18`로 유지
  - `00:11, 00:09` 유입
    - 이 이벤트를 처리해야할지 고민 필요
  - `00:14, 00:25, 00:28` 유입
    - 스트리밍 시계가 최대 `00:28`로 증가
- 일반적으로 **구조적 스트리밍**은
  - **이벤트**에서 타임스탬프로 선언된 필드의
  - **단조 증가 상한**을 유지하여
  - 이벤트 시간으로 처리된 **이벤트의 타임라인**을 유추
- 이 **비선형 타임라인**은
  - 이 장의 **시간 기반 처리 기능**에 사용되는 판결 클럭
- 이벤트 소스의 시간 흐름을 이해하는 **구조적 스트리밍**기능은
  - 이벤트 처리 시간에서 **이벤트 생성**을 분리
- 과거 이벤트 시퀀스를 재생하고
  - 구조적 스트리밍으로 하여금 모든 **이벤트 시간 집계**에 대해 올바른 결과 생성 불가
- 예시로, 몇 분 안에 `일주일 분량의 이벤트를 재생`할 수 있으며
  - 시스템에서 **일주일**과 일치하는 결과를 얻을 수 있음
- 시간이 **컴퓨터 시간에 의해 통제**된다면, 이것은 **불가능**

## 12.2. 이벤트 시간의 사용
- 구조적 스트리밍에서는 **시간 기반 집계**와 **상태 관리**라는 영역에서
  - 이벤트 시간에 대한 기본 지원 기능 활용 가능
- 위 두 경우 모두
  - 첫번째 단계는 구조적 스트리밍에 적합한 형식의 **데이터 필드**를 **타임스탬프**로 이해하는 것
- `Spark SQL`은 `java.sql.Timestamp`를 `Timestamp` 타입으로 지원
  - 다른 기본 유형의 경우, 이벤트 시간 처리에 값을 사용하려면, `Timestamp`로 변환 필요

#### TABLE.12.1. Timestamp 필드 획득하기

>**ts 기본 타입**|**SQL 함수**
>-----|-----
>Long|$"ts".cast(TimestampType)
>yyyy-MM-dd HH:mm:ss|$"ts".cast(TimestampType)
>yyyy-MM-dd HH:mm:ss(대안)|to\_timestamp($"ts")
>사용자 정의 형식의 문자열 예시|to\_timestamp($"ts", "dd-MM-yyyy HH:mm:ss")

## 12.3. 처리 시간
- **이벤트 시간**은 이벤트가 생성된 **타임라인**과 관련이 있음
  - **처리 시간**과 무관
- **처리 시간**은
  - 엔진에 의해 이벤트가 수집될 때의 타임라인
  - 이벤트 스트림을 **처리하는 컴퓨터의 시계를 기반**으로 함
- **이벤트 데이터**에 시간 정보가 포함되지 않은 경우가 있지만
  - 구조적 스트리밍에서 제공하는 기본 시간 기반 기능을 여전히 활용하려 함
- 이럴 경우 **처리 시간**(`processing-time`) 타임스탬프를
  - **이벤트 데이터**에 추가하고
  - 해당 타임스탬프를 **이벤트 시간**으로 활용할 수 있음
- `currnet_timestamp` SQL을 사용하여, 처리 시간 정보 추가하는 예시
  ```scala
  // 처리 시간 Timestamp 추가
  val timeStampEvents = raw.withColumn("timestamp", current_timestamp())
  ```

## 12.4. 워터마크
- 아래 질문에 대응하기 위해 **워터마크** 개념이 **구조적 스트리밍**에 도입됨
  - 얼마나 늦어야, 아주 늦었다라고 판단할지?
  - 전체 집계를 완료하기 전에 얼마나 오랫동안 **부분 집계**를 **유지**할지?
- 워터마크
  - **이벤트**가 너무 늦음을 선언하기 전에
  - 이벤트를 **기다리는 시간**을 결정하는 **임계값**
- 워터마크를 벗어난 것으로 간주되는 이벤트는 **폐기**
- 기본적으로 **내부 시간 표현**에 따라 임계값으로 계산됨
- 워터마크 라인은
  - **이벤트 시간**정보에서 유추된 **이벤트 시간 타임라인**에서 변경된 라인
  - 내부 이벤트 타임라인보다, 이벤트 시간기준 아래쪽에 위치(허용 범위)
  - 워터마크 라인보다 아래에 위치한 이벤트는, `너무 늦음`으로 판단,
    - 이벤트 스트림을 소비하는 계싼에는 고려되지 않음
- `timestamp` 필드를 **워터마크**에 해당하는 시간 임곗값과 연결하여, 워터마크를 선언 
  ```scala
  val timeStampEvents = raw.withColumn("timestamp", $"ts".cast(TimestampType))
                           .withWatermark("timestamp", "5 minutes")
  ```

## 12.5. 시간 기반 윈도우 집계
- 스트림 환경에서의 질문
  - `x가 몇개나 있습니까?` - X
  - `15분 간격으로 x가 몇개나 있는지` - O
- **이벤트 시간 처리**를 사용하면
  - **데이터 부분 집계**를 유지하고
  - 선택된 **출력 모드**에 해당하는 의미를 사용하여
  - **다운스트림 소비자**를 업데이트

### 12.5.1. 시간 기반 윈도우 사용하기
- `tumbling` 및 `sliding` 윈도우
- `API 관점`에서 윈도우 집계는
  - **윈도우 함수**를 **그룹화 기준**으로 사용하여 선언
  - 이벤트 시간으로 사용하려는 필드에 **윈도우 함수**를 적용해야 함

#### CODE.12.1. 전체 평균 계산
```scala
val perMinuteAvg = timeStampEvents
  .withWatermark("timestamp", "5 minutes")
  .groupBy(window($"timestamp", "1 minute"))
  .agg(avg($"pressure"))

perMinuteAvg.writestream.outputMode("append").format("console").start()
```
- 윈도우 집계의 결과
  - 각 결과 윈도우의 `start, end timestamp`로 표시된 **윈도우 기간**이 포함되어 있음

### 12.5.2. 간격이 어떻게 계산되는지에 대한 이해
- 윈도우 간격은 사용한 시간 단위의 다음 **상위 시간 크기**에 해당하는
  - `s/m/h/d`의 **시작에 연계**
  - `e.g. window($"timestamp", "15 minutes")`
  - 시간의 시작에 맞춰 `15min`의 간격을 생성
- 첫 번째 간격의 **시작 시간**은
  - 데이터 손실 없이 윈도우 정렬을 조정하기 위한 **과거 시간**
  - 첫 번째 간격이 **일반적인 데이터 간격의 일부만 포함**할 수 있음을 의미
- `e.g. 100 message/sec, 15min = 90K message, 첫 윈도우는 단순히 그 일부`
- 윈도우의 **시작 간격**은
  - 시작 시에 **수용적**이고, 종료 시에 **베타적**
- **구간 표기법**(interval notation)에서
  - `[start-time, end-time)`으로 기록됨


### 12.5.3. 복합 집계키 사용

#### CODE.12.2. 관측소당 평균 계산
```scala
val minuteAvgPerStation = timestampEvents
    .withWatermark("timestamp", "5 minutes")
    .groupBy($"stationId", window($"timestamp", "1 minute"))
    .agg(avg($"pressure") as "pressureAvg", avg($"temp") as "tempAvg")

minuteAvgPerStation.writeStream.outputMode("append").format("console").start
```

### 12.5.4. 텀블링 윈도우와 슬라이딩 윈도우
- `window`
  - `TimestampType` 타입의 `timeColumn`과
  - 추가 파라미터를 사용하여 **윈도우의 기간**을 지정하는 SQL 함수
- `window`의 시그니처
  ```scala
  window(timeColumn: Column,
         windowDuration: String,
         slideDuration: String,
         startTime: String)
  ```
  - 이 메서드의 오버로드된 정의는 `slideDuration` 및 `startTime`을 선택적으로 생성
- 이 `API`를 사용하면 **텀블링 윈도우**와 **슬라이딩 윈도우**라는 두 가지 유형의 윈도우 지정 가능

#### 텀블링 윈도우
- 시간을 겹치지 않는 **연속된 기간**으로 분할
- `15분마다 총 카운트`
- 오직 `windowDuration` 파라미터만 제공하여 **텀블링 윈도우**를 지정
  ```scala
  window($"timestamp", "5 minutes")
  ```
  - 5분마다 하나의 결과 생성

#### 슬라이딩 윈도우
- `텀블링 윈도우`와 달리 `슬라이딩 윈도우`는 시간 간격이 겹친다
- 간격의 크기는 `windowDuration` 시간에 의해 결정
- 해당 간격의 스트림에서 모든 값은 **집계 작업**에 고려
- `slideDuration` 중에 도착하는 요소를 추가하고
  - `가장 오래된 슬라이스`에 해당하는 요소를 제거한 다음
  - 윈도우 내에 데이터에 집계를 적용하여
  - 각 `slideDuration`에서 결과를 생성
- 예시 코드
  ```scala
  window($"timestamp", "10 minutes", "1 minute")
  ```
  - `10분` 분량의 데이터를 사용하여 `1분`마다 결과를 생성
- **텀블링 윈도우**는 `windowDuration`과 `slideDuration`의 값이 같은 슬라이딩 윈도우의 특별한 경우
  ```scala
  window($"timestamp", "5 minutes", "5 minutes")
  ```
- `windowDuration < slideInterval` - X
  - `org.apache.spark.sql.AnalysisException` 발생

#### 간격 오프셋
- `startTime`이라는 세번째 파라미터는
  - **윈도우 정렬**을 **오프셋**하는 방법 제공
- **12.5.2** `간격이 어떻게 계산되는지에 대한 이해`에서
  - 윈도우 간격이
  - **상위 다음 시간 크기로 연계**되어 있음을 확인
  - `startTime`을 사용하면, 표시된 시간만큼 **윈도우 간격을 오프셋**할 수 있음
- 예시: 슬라이드 지속 시간이 `5분`인 `10분` window을 `2분씩 오프셋`하여 다음과 같은 시간 간격 생성
  ```scala
  // 00:02-00:12, 00:07-00:17, 00:12-00:22, ...
  window($"timestamp", "10 minutes", "5minute", "2 minutes")
  ```
- `startTime < slideDuration` 이어야 함
- 잘못된 구성이 제공되면 `org.apache.spark.sql.AnalysisException`이 발생
- `slideDuration`이
  - 윈도우가 보고되는 주기성을 제공한다는 점을 고려하면
  - 우리는 **기간 자체보다 작은 시간 동안**만 그 기간 상쇄 가능

### 12.6. 레코드 중복 제거
- 구조적 스트리밍은 **스트림**에서
  - **중복 레코드**를 제거하는 내장 기능 제공
- 본 키를 언제 폐기하는 것이 안전한지 결정하는 **워터마크**를 지정할 수 있음
  ```scala
  val deduplicatedStream = stream.dropDuplicates(<field>, <field>, ...)
  ```
- 그럼에도, 이 기본적인 방법은 **잠재적**으로 제한이 없는 고유 레코드를 정의하는 필드 집합에 대해
  - `수신된 모든 값을 저장`해야하므로 **권장하지 않음**
- 보다 강력한 대안은 `dropDuplicates` 함수 전에 **스트림에 워터마크 지정**
  ```scala
  val deduplicatedStream = stream
        .withWatermark(<event-time-field>, <delay-threshold>)
        .dropDuplicates(<field>, <field>, ...)
  ```
- 워터마크를 사용하는 경우
  - **워터마크**보다 **오래된 키**를 삭제할 수 있으므로
  - **상태 저장소**에서 **스토리지 요구 사항**을 제한할 수 있음

### 12.7. 요약
- 구조적 스트리밍이 **이벤트 데이터**에 포함된 **시간**을 활용하기 위해
  - API가 제공하는 **이벤트 시간**과 기능의 개념을 어떻게 구현하는지 살펴봄
- 내용
  - 이벤트 시간을 사용하는 방법, 필요할때 **처리 시간**을 **되돌리는 방법**
  - **워터마크**
    - 어떤 이벤트가 `너무 늦고` 어떤 상태 관련 데이터가
      - 스토어에서 퇴출될 수 있는지 판단할수 있는 개념
  - 윈도우 작동에 대한 **다양한 구성**과 **이벤트 시간**과의 연결 확인
  - 데이터 중복 제거 기능이 **워터마크**를 사용하여
    - **상태**를 유지하는 방법
- **이벤트 타임 프로세싱**은
  - **시간, 순서, 지연 처리**의 복잡성을
  - 사용하기 쉬운 API로 **캡슐화**한 구조적 스트리밍에 내장된 강력한 기능 집합
- 그럼에도 **내장 함수**가 특정 **상태 기반 프로세스**를 구현하기에 충분하지 않는 경우가 존재
- 그러한 경우, **구조적 스트리밍**은 다음장에서 볼 수 있듯
  - 임의의 상태 기반 프로세스를 구현하는 **고급 기능** 제공
