## [CHAP.01] 스트림 처리 소개
- 스트림 처리 기술읠 채택
  - 운영 환경 변화에 대응하고 적응하는데 필요한 시간을 개선하기 위한 비즈니스 필요성 증대
  - 데이터를 생성하는 능력이 데이터를 이해하는 능력을 훨씬 능가

### 1.1. 스트림 처리란
- **무한 데이터**(`unbounded data`)로부터 정보를 추출하는데 사용하는 규율 및 관련 기술 집합
- 시간 경과에 따른 **이벤트 흐름 형태**로 처리 시스템에서 수신되는 데이터를 관찰하며
  - 이를 **데이터 스트림**이라 한다
- **유한 데이터**(bounded data)
  - 알려진 크기의 데이터셋
  - 요소의 수를 셀 수 있음

#### 1.1.1. 배치 처리와 스트림 처리
- 배치 처리(batch-processing)
  - 유현 데이터 셋의 계산 분석 참조
  - 일부 **스토리지 형식**에 전체적으로 사용 가능하고, **검색 가능**
  - 데이터 셋의 크기와, 프로세스의 지속시간이 제한 되어 있음을 의미
- 스트림 처리(stream-processing)
  - 데이터가 시스템에 도착할 때의 데이터 처리에 대해 관심 있음
  - 데이터 스트림의 무한한 특성을 고려할 때
    - **스트림 프로세서**는 스트림이 새로운 데이터를 제공하는 한 지속적으로 작동
  - 스트림 처리 시스템은 **프로그래밍**과 **운영 기술**을 적용하여
    - 제한된 컴퓨팅 리소스로 **무한한 데이터 스트림 처리**를 가능하게 함

#### 1.1.2. 스트림 처리에서의 시간의 개념
- 유휴 데이터
  - 파일 형식, 데이터 베이스의 내용 또는 기타 레코드 종류
  - '과거'의 데이터
- 사용 중인 데이터
  - 차량의 센서 또는 GPS 신호 측정과 같이 **연속적**으로 생성되는 신호 시퀀스
  - 데이터 추론이 어려움
- 스트림 처리 프로그램은
  - 입력 내용을 **시간이 지남에 따라 관찰되는 무한 길이의 신호 시퀀스**라고 함
- `이벤트가 생성된 시간`과 `스트림 처리 시스템에 의해 처리되는 다른 타임라인`이 존재
- **이벤트 시간**
  - 이벤트가 생성 되었을 때의 시간
  - 시간 정보는 이벤트를 생성하는 장치의 **로컬 시간**에 의해 제공
- **처리 시간**
  - 이벤트가 **스트림 처리 시스템**에 의해 처리되었을 때의 시간
  - 이는 처리 로직을 실행하는 **서버의 시간**을 의미
  - 일반적으로 **처리 지연 계산**과 같은 기술적인 이유 또는
    - **중복된 출력**을 결정하는 기준으로 적합함
- 이벤트를 서로 관련시키거나 **순서**를 정하거나, **집계**해야할 떄
  - 이러한 타임라인 간의 차별화는 매우 중요함

#### 1.1.3. 불확실성의 요인
- 일반적으로 **스트리밍 시스템**은 일정한 간격으로,
  - 한 번에 또는 특정 리듬에 따라 입력을 생성할 필요가 없다
- 즉, 컴퓨팅에는 일반적으로 **비용**이 들기 때문에,
  - 갑작스런 도착과 처리에 필요한 컴퓨팅 리소스를 일치시키는 **최대 로드 예측**은 어려움
- **불확실성 처리**는 **스트림 처리**의 중요한 측면
  - 시간이 지남에 따라 **전달된 이벤트**로 관찰되는 **무한 데이터**(비경계 데이터) 스트림에서 정보 추출이 가능
  - 그럼에도, 데이터를 수신하고 처리할 때, **이벤트 시간**의 부가적인 복잡성과
    - 무한 입력으로 인해 발생하는 **불확실성**을 처리해야 함

### 1.2. 스트림 처리 예제
- 어떤 경우에도 가능한 한 **최신의 데이터**를 소비할 때가 더 좋다고 주장 가능

### 1.3. 데이터 처리의 확장
- 확장성 있고 안정적인 데이터 처리를 위한 토대를 마련한 컴퓨터 모델인 **맵리듀스**

#### 1.3.1. 맵리듀스
- `2003.02`, 구글의 대규모 클러스터 분산 처리 시스템 -> **맵리듀스** 개발
- 이는 **프로그래밍 API**이자, 구성 요소 집합으로서
  - **분산 시스템**에 대한 프로그래밍을 모든 이전 작업보다 쉽게 만듦
- 핵심 두가지 함수
  - **Map**
    - 컬렉션의 모든 요소에 적용될 함수를 **인수**로 받는다
    - 컬렉션의 요소는 분산 시스템을 통해
      - 분산된 방식으로 executor machine당 **하나의 chunk**로 읽힘
    - local chunk에 상주하는 컬렉션의 모든 요소가
      - 그들에게 적용된 함수를 보고 `executor`가 있는 경우 해당 app의 결과를 내보냄
  - **Reduce**
    - 두가지 인수 사용
      - 중립 요소로서, 빈 컬렉션이 넘겨지면 `reduce`연산이 리턴
      - 집계의 **현재값**인 컬렉션의 새 요소를 가져와서 **새로운 집계**로 묶는 집계 연산

#### 1.3.2. 교훈 : 확장성 및 내결함성
- MapReduce의 장점
  - 간단한 API
  - 높은 표현력
  - `프로그래머`부터 `라이브러리 디자이너`까지 프로그램을 배포하는데 어려움이 줄어듦
  - **복원력**이 모델에 내장됨
- 주요 속성
  - **확장성**
    - 데이터셋이 증가함에 따라, 안정적인 처리 성능을 유지하기 위해
    - 시스템 클러스터에 더 많은 리소스 추가 가능
  - **결함 허용**
    - system은 부분적인 **장애**를 버텨내고 **복구**할 수 있음
    - 모든 데이터가 **복제**됨
    - 데이터 전송 executor가 손상되면
      - 손상된 executor에서 실행중인 작업을 **다시 시작**하면 됨
    - `master`가 해당 작업을 추적하기 때문에, **일정 변경 이외에 특정 문제가 발생하지 않음**
- 이 두 특성이 결합되면,
  - 시스템은 기본적으로 **신뢰할 수 없는 환경**에서도
  - **워크로드**를 지속적으로 유지 가능
    - **스트림 처리**에도 필요한 속성

### 1.4. 분산 스트림 처리
- `맵 리듀스를 이용한 모델`을 사용한 `스트림 처리`와 `일반적인 배치 처리`를 사용한 스트림 처리의 차이
  - 배치 처리에서는 **스트림**을 사용하여, 전체 데이터 셋에 엑세스 할 수 있지만
    - 언제나 데이터셋의 **일부**만 볼 수 있다는 것
- 위 상황은 **분산 시스템**에서 악화됨
  - 일련의 `executor` 사이의 처리를 부하를 분산시키기 위해
  - **입력 스트림**을 파티션으로 분할
  - 각 executor는 전체 스트림의 **일부**만 볼 수 있음
- 분산 스트림 처리 프레임워크의 과제
  - 사용자에게 이런 복잡성을 숨기고, 스트림 전체를 추론할 수 있도록 하기

#### 1.4.1. 분산 시스템에서 상태 기반 스트림 처리
- 궁극적인 오류 복구는 **최종 결과에 영향을 줄 수 없음**
  - 잘못 복구된 시스템의 부작용으로, 잘못된 결과 유도는 안됨
- 스트림 처리의 유의점
  - 시간이 지나도 상태가 보존되도록 보장
  - 부분적인 시스템 장애 발생시에도, 데이터의 일관성이 보장

### 1.5. 아파치 스파크 소개
- 대규모 데이터 처리를 위한 빠르고 안정적이며 `fault tolerance`이 있는 분산 시스템 프레임워크

#### 1.5.1. 첫 번째 물결: 기능적 API
- 스파크 메모리 모델
  - RAM을 사용하여 데이터가 처리될 때 **캐시**하므로
  - 배치성 작업 부하를 처리하기 위한 하둡 맵리듀스보다 100배 빠름
- 탄력적 분산 데이터셋(Resilient Distributed DataSet, RDD)

### 1.5.2. 두 번째 물결:SQL
- SparkSQL

### 1.5.3. 통합 엔진
- `polyglot`접근과 호환되는 배치와 스트리밍 기능을 제공
- scala, java, python, R

### 1.5.4. Spark Component
- Spark Core
  - 핵심 실행 엔진, executor로 불리는 컴퓨터 리소스 클러스터에 연산을 배포하는데 사용하는 하위 기준의 기능적 API set
  - Yarn, Mesos, k8s, standalone으로 구성 가능
- Spark SQL
  - 상위 레벨 dataset, datafram API를 구현
  - Catalyst 쿼리 엔진과, Tungsten 프로젝트 코드 생성 및 메모리 관리를 통해
    - 얻게 되면 일련의 성능 향상 도입
- MLlib, GraphFrame, ...

### 1.5.5. Spark Streaming
- micro batch model
  - elemnt-at-time과 대조
- `DStream`(Discretized Stream)을 도입

### 1.5.6. 구조적 스트리밍
- Spark SQL 추상화 위에 구축된 스트림 프로세서
- `DataSet`, `DataFrame` API를 확장
- 선언적 모델을 사용하여 stream또는 streamSet에서 데이터를 수집
- Api를 최대한 활용하려면 스트림의 데이터에 대한 스키마 지정이 필요
- 일반 변환 모델을 지원할 뿐만 아니라, 이벤트 시간, 스트리밍 조인 및 기본 런타임과의 분리와 같은 스트림별 기능
- 최신 연속 처리 백엔드는 실시간 연속 실행 모드를 실험적으로 지원
- 구조적 스트리밍은
  - 스트림 처리를 동일한 수준의 배치 지향 application으로 가져오는 통합된 모델을 제공하여
  - 스트림 처리에 대한 많은 추론 부담을 줄임