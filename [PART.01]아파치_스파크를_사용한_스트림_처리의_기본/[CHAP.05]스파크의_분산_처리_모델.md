# [CHAP.05] 스파크의 분산 처리 모델
- 분산 처리 시스템으로서의 스파크
  - 임의의 **워크로드**를 실행하기 위해 **컴퓨팅 리소스**의 **가용성**과 **주소 지정성**에 의존

## 5.1. 클러스터 매니저를 활용한 아파치 스파크 실행
- 클러스터에 의존한 일련의 장비들
  - 일반적인 목적을 가지며
  - 스트리밍 어플리케이션의 **runtime binary**와 **실행 스크립트**(provisioning)을 수신해야 함
- 현대적인 클러스터는
  - 자동으로 관리 되며 `multitenancy`상황에서 많은 수의 장비가 포함됨
  - 많은 이해 관계자가 비즈니스 당일 다양한 시간에 **동일한 클러스터**에 액세스하여 사용하기 원한다는 것을 의미
  - 클러스터는 **클러스터 매니저**에 의해 관리
- 클러스터 매니저
  - 다수의 사용자로부터 **이용 요청을 받음**
  - 일부 **리소스에 연결**
  - 일정 기간동안 사용자를 대신하여 **리소스 예약**
  - 사용자가 사용 가능한 여러 리소스에 **사용자 어플리케이션 배치**
  - 사용 가능한 시스템 풀 중에서
    - 사용자 요청의 **최상의 위치 파악**
  - 여러 사람이 동일한 물리적 인프라 공유시,
    - 사용자 어플리케이션을 **안전하게 격리**
- 매니저의 장점을 살리려면
  - 업무의 단편화
  - 최적의 배치
  - 가용성
  - 선점 및 우선순위 지정
- 아파치 스파크는
  - 기존 **클러스터 매니저**를 활용하여 클러스터에 **워크로드**를 분산

### 5.1.1. 클러스터 매니저의 예
- 매니저 목록
  - yarn
    - apache hadoop project에서 태어난 비교적 성숙한 클러스터
  - mesos
    - **리눅스 컨테이너 기술**을 기반으로한 CM
    - 아파치 스파크의 존재 이유였었음
  - k8s
    - **서비스 지향 API**
    - 구글의 실제 업무에서 탄생하여 **CNCF**(Cloud Native Computing Foundation)을 지향
- 아파치 스파크가 **배포판**으로서, 자체의 **클러스터 매니저**를 포함함
  - 이는 스파크가 고유한 **배포 조정자 역할**을 할 수 있음을 의미
- 이후 내용
  - 스파크 자신의 클러스터 매니저와, 이들의 **특별한 목적**이
    - mesos, yarn, k8s 같은 **프로덕션 클러스터 매니저**에 비해
    - 내결함성 또는 멀티테넌시 영역에서 더 적은 책임을 지는 것에 대해 어떤 의미를 가지는지
  - 분산 스트리밍 어플리케이션에서 예상되는 **표준 수준의 전달 보장 방법**
    - 서로 어떻게 다르며, 어떻게 보증 하는지
  - 마이크로배칭이 10년된 **대량 동기화 처리**(BSP) 모델에서 어떻게 탄생했는지
    - 스파크 스트리밍에서 구조적 스트리밍으로 진화하는 경로 구체화

## 5.2. 스파크 자체 클러스터 매니저
- **로컬 클러스터 매니저**
  - 테스트 목적으로 CM(or RM)의 기능을 모방
  - 몇 개의 사용가능한 코어가 잇는 **로컬 시스템**에 의존
  - 스레딩 모델을 사용하여 **분산 시스템 클러스터**의 존재 재현
  - 일반적으로 사용자 노트북에서만 실행
- **독립 실행형 클러스터 매니저**
  - 비교적 간단한 스파크 전용 CM
  - 리소스 할당의 슬라이스 및 **가용성이 제한적**
  - spark executor가 배포되고 시작된 **전체 작업자 노드**를 보유하고, 사용할 수 있음
  - executor가 미리 배치되었을 것으로 예상하며,
    - 그 `.jar`를 **새 장비로 운송하는 것은 그 범위 밖**
  - 특정 수의 executor를 넘겨 받아,
    - 그것에 대한 작업을 실행할 수 있는 능력을 가짐
  - production 배포에는 권장되지 않음
- 스파크는 **스케줄링**하는 대상이 **사용자 프로그램**에서
  - 추출한 연산의 분배 단위인 **태스크**라는 점에서 **태스크 스케줄러**임
- 스파크는 mesos, yarn, k8s를 포함한 CM을 통해
  - 통신하고, 배포하고
  - 경우에 따라 자체 독립형 CM을 허용함
- 이 통신의 목적은 다수의 `executor`를 예약하는 것
  - 이는 스파크가 **동일한 크기의 연산 리소스**를 이해하는 단위로써
  - 가상의 **노드**와 같은 종류의 것
- **예약된 리소스**는 CM이 다음과 같이 제공할 수 있음(3)
  - 프로세스가 리소스 사용량을 측정하지만
    - 기본적으로 서로의 리소스에 액세스하는 것을 막지 못하는 **제한된 프로세스**
    - yarn의 일부 기본적인 사용 사례
  - **컨테이너**(e.g. mesos, k8s)는 리눅스 커널의 `cgroup`와 `namespace`에서 탄생하고
    - `Docker`프로젝트에서 가장 인기 있는 `iteration`으로 알려져 있는 **경량 리소스 예약 기술**
  - **가상 머신**(VM)에 위와 같은 기능 배포 가능
    - 그 자체로 **코어** 및 **메모리** 예약 기능 제공

### 클러스터 작업
- 위 세가지 기법(3)에 수반되는 서로 다른 수준의 **고립**은 의미 있음
- 엔터프라이즈급 운영 클러스터 관리 영역에 서
  - `작업 대기열`, `우선순위`, `멀티태넌시` 옵션 및 사전 예방과 같은 개념을 접할 때
  - 이 개념은 `CM`의 영역이므로, spark를 초점에 맞춘 자료에서는 언급되지 않음
- 여러 사람과 공유하는 `cluster`에서 **좋은 시민**이 되려면, cm의 세부 사항을 파악하는 것이 중요
- 많은 팀이 여러 리소스를 놓고 경쟁하는 동안, 적절하게 클러스터를 운영하는 법
  - 이 장에서 소개하는 참고 자료와, 해당 지역의 `DevOps`팀을 살펴보아야 함

## 5.3. 분산 시스템에서의 복원력과 내결함성 이해
- 분산된 어플리케이션에서는 **복원력**와 **내결함성**이 절대적으로 중요
- **탄력적 어플리케이션**은
  - 분산 환경의 지연 및 중요하지 않은 장애에도 프로세스를 진행할 수 있음
- **내결함성**이 있는 어플리케이션은
  - 하나 또는 여러 노드의 계획되지 않은 종료에도 불구하고
  - 성공적으로 프로세스를 완료할 수 있어야 함
- 이 **복원력**은
  - 앱이 `결정되지 않은 시간동안` 작동해야 하는 경우, **스트림 처리**와 연관
    - `결정되지 않은 시간 = 데이터 소스의 수명 주기와 연관`
- 스트리밍 방식으로 데이터를 처리하는 시스템은 **장기간 중단 없이 실행 되어야 함**

### 5.3.1. 장애 복구
- 내결함성의 맥락에서
  - 하나의 특정 노드의 **장애**로부터 **복구하는데 걸리는 시간**을 이해하는 것도 중요
- 스트림 처리 = 실시간으로 데이터가 계속 생성
- 배치 컴퓨팅 실패를 처리하기 위해
  - 항상 처음부터 다시 시작할 기회를 갖고
  - 연산 결과를 얻는게 더 시간이 오래 걸림
- 원시적인 형태의 **내결함성**은
  - 배포에서 **특정 노드의 고장을 감지하고, 연산을 중지하고, 처음부터 다시 시작**
  - 예상 시간보다 오래 걸릴 수 있으나, 서두르지만 않는다면 이해 가능한 시간
- 스트림 처리를 위해 **복구 중인 클러스터**가
  - 아직 어떠한 처리도 수행할 준비가 되지 않았다면,
  - **데이터를 계속 수신**하여 잠재적으로 저장해야 함
  - 이는 **높은 처리량**에서 **문제**를 발생시킬 수 있음
- 처음부터 다시 시작하려고 하면
  - 어플리케이션 시작 이후뿐 아니라, 
  - 그 자체로 문제가 발생할 수 있는 **과거 데이터**를 재처리하는 동안에 관찰된 **모든 데이터 재처리**가 필요하면
  - 우리가 따라 잡으려고 애쓰는 동안 생성된
    - 새로운 데이터를 계쏙 수신하고 저장하는데 필요할 것
- 처음부터 다시 시작하는 이 패턴은
  - **스트리밍에 있어서 매우 다루기 힘든 것**
- 노드가 사용할 수가 없거나, 작동하지 않는 경우에
  - **최소한의 연산만 재시작**하는 스파크의 능력이 주의

### 5.3.2. 내고장성에 대한 클러스터 매니저 지원
- yarn, mesos, k8s의 CM에 유사한 기능이 존재하더라도
  - **스파크의 내결함성 보장을 이해**하는 것은 중요
- CM이 오류를 보고하고, 그러한 예외에 대처하기 위한 **새로운 리소스**를 요청할 수 있는 프레임워크와
  - 밀접이 관련되어, 내고장성을 돕는다고 생각할 수 있음
  - 스파크는 그러한 능력을 가짐
- 예시로
  - yarn, mesos, k8s와 같은 **운영 클러스터 매니저**는
    - 노드의 엔드포인트를 검사하고, 노드의 `자체 준비 상태`와 `활성 상태`를 보고하도록 요청함으로써
    - 노드의 **장애를 감지**할 수 있는 기능 존재
  - 이러한 CM이 **장애를 감지**하고 **여유 용량**을 가진 경우
    - 해당 노드를 **스파크**에서 사용할 수 있는 **다른 노드**로 교체할 것
  - 이 특정 작업은 스파크의 `executor code`가
    - 다른 노드에서 새로 시작된 다음, **기존 스파크 클러스터에 연결하려고 시도**함을 의미
- CM은 자신이 예약한 노드에서 실행되는 app에 대한
  - 자기성찰 기능을 가지고 있지 않음
  - 그 책임은, 사용자의 코드를 실행하는 container에 한정
- 이 책임의 경계는 **스파크 복원 기능**의 시작점
- 장애가 발생한 노드에서 복구하려면, 스파크는 다음을 수행해야 함
  - 해당 노드가 **체크포인트된 파일 형태**로 재생산되어야 하는 상태를 포함하는지 여부 확인
  - 어느 단계의 잡에서 **노드가 컴퓨팅에 다시 참여**해야하는지 이해
- 여기서 목표는
  - CM에 의해 노드가 **교체**되는 경우
  - 스파크가 이 **새로운 노드를 활용**하고
  - 그 노드에 연산을 **분산**시킬 수 있는 기능을 탐구해야 함
- app으로서의 **스파크의 책임**에 초점을 맞추고
  - 필요한 경우에만 CM의 기능을 강조
- 예시로 노드는 `하드웨어 장애`또는 노드의 작업이 단순히 높은 수준의 **잡**에 의해 `선점되었기 때문`에 교체될 수 있음
  - apache spark는 그 **이유**를 모른채 그 **방법**에만 초점을 맞춤

## 5.4. 데이터 전송 의미론
- 스트리밍 모델에서 볼 수 있는 것처럼
  - 스트리밍 잡이 실시간으로 **생성되는 데이터**를 기반으로 작동한따는 것은
  - **중간 결과**가 해당 스트리밍 파이프라인의 **소비자**(consumer)에 정기적으로 제공될 필요가 있는 것을 의미
- 그러한 결과들은 일부 **클러스터**에 의해 만들어지고 있음
- 이상적으로는 **관측 가능한 결과**가
  - 데이터 도착과 관련하여 일관성 있으며
  - 그때마다 즉시 처리할 수 있고
  - 실시간으로 유지되길 바람
- 이것은 우리가 정확한 결과를 원하고,
  - 가능한 한 **빨리 결과**를 원한다는 것을 의미
- 그러나 분산 연산은 앞서 언급한 대로 때때로 개별 노드 장애뿐 아니라
  - 같이 클러스터의 일부분이 클러스터의 다른 부분과 통신할 수 없는 **네트워크 파티션**과 같은 상화에 직면한다는 점에서 자체적인 문제를 안고 있음
- **드라이버/익스큐터** 아키텍처를 사용하여 설계됨
  - 특정 머신에서 드라이버는 사용자의 `job submission`과 함께 `job progression`을 추적하는 작업을 수행하며,
    - 데이터가 도착할 때 해당 프로그램의 연산이 이루어짐
  - 그러나 네트워크 파티션이 클러스터의 일부를 분리하는 경우 **드라이버**는 초기 클러스터를 구성하는
    - 익스큐터의 일부만 추적할 수 있음
  - 파티션의 다른 부분에서 우리는 완전히 기능할 수 있지만,
    - 단순히 그들의 계산 과정을 드라이버에 설명할 수 없는 노드를 발견함
- 이는 새로운 작업을 받지는 못하지만
  - 이전에 주어진 여산의 **일부 파편**을 완성하는 과정에는 있을 수 있는 좀비 노드와 같은 **흥미로운 사례**를 만들어냄
  - 파티션을 대해 알지 못한 채 그들은 **익스큐터**가 원하는대로 결과를 보고
  - 이러한 결과 보고가 **드라이버**를 병목현상으로 만들까봐 **드라이버**를 거치지 않는 경우가 있기 때문ㅇ
    - 이러한 좀비 결과 보고가 성공할 수 있음
- `bookkeeping`의 한 지점인 **드라이버**는 
  - **좀비 익스큐터**가 여전히 동작하고 결과를 보고하는 것을 알지 못하기 때문에
  - 손실된 익스큐터가 새로운 노드에서 수행해야 했던 것과 **동일한 작업**을 다시 예약함
- 이것은 좀비 머신들이 파티셔닝을 통해 분실되고 재조정된 작업이 있는
  - 머신들은 둘 다 같은 결과를 보고 하는 `double-answering` 문제를 야기
- 스트림 처리 어플리케이션과 **상태 체크포인트**에서 출력이 한 번의 원자적인 작동으로 완료될 수 없을 때
  - **체크 포인트**와 **출력** 사이에 고장이 발생하면 **데이터 손상**이 발생함
- 처리 포인트
  - **최소 한 번**
    - 스트림의 모든 요소가 `한 번 이상 처리`하도록 함
  - **최대 한 번**
    - 스트림의 모든 요소가 `한 번 이하로 처리`하도록 함
  - **정확히 한 번**
    - `최소 한 번`과 `최대 한 번`의 조합
- 최소 한 번 처리하는 것은 모든 초기 데이터가 처리되었는지 확인하는 개념이며,
  - 앞서 언급한 노드 장애를 다룸
- 이미 언급했듯, `스트리밍 프로세스`가 `일부 노드를 교체`하거나 `일부 데이터를 다시 연산`해야 하는
  - `부분적인 장애`를 겪을 때 `데이터 수집을 계속 유지`하면서
  - 손실된 연산 단위를 재처리해야 함
- 그 요구사항은 적어도 한 번 처리하지 않는 경우
  - 특정 조건에서 데이터를 잃을 가능성이 있음을 의미
- **비대칭 개념**은 최대 한 번 처리하는 것
  - 최대 한 번 처리되는 시스템은
    - **재조정**된 노드와 동일한 결과를 반복하는 **좀비 노드**를 일관성 있게 처리하여
    - 하나의 결과 집합만 추적하도록 보장
  - 그들의 결과가 **어떤 데이터였는지** 추적함으로써
    - 반복된 결과를 폐기할 수 있다는 것을 확실히 할 수 있고,
  - 동시에 **최대 한 번 처리 보증**을 제공할 수 있음
- 이를 달성하는 방법은 **결과 수신**의 **최종 단계**에 적용되는 **멱등**(`idempotence`) 개념의 의존
- 멱등은 어떤 데이터에든 **두 번**또는 **그 이상** 적용하면
  - **처음과 같은 결과**를 얻을 수 있도록 **함수를 규정**
- 이는 결과를 보고하는 **데이터를 추적**하고,
  - 스트리밍 프로세스의 출력에 **북키핑 시스템**을 갖추는 것으로 달성할 수 있음

## 5.5. 마이크로배칭과 한 번에 한 요소
- 스트림 처리에 대한 두가지 중요한 접근 방법
  - **대량 동기화 처리**
  - **한 번에 한 레코드 처리**
- 이 두가지 아이디어를
  - spark가 **스트림 처리**를 위해 보유하고 있는
  - 두 개의 API인 **스파크 스트리밍** 및 **구조적 스트리밍**에 연결하는 것

### 5.5.1. 마이크로배칭: 대량 동기화 처리의 적용
- **스파크 스트리밍**은 스파크의 보다 성숙한 스트림 처리 모델로서
  - **대량 동기화 병렬 처리**(BSP; Bulk Synchronous Parallelism) 시스템
- **BSP**의 요지
  - 비동기 작업의 **분할 배포**
  - 일정한 간격으로 들어오는 **동기식 장벽**
- **분할**은 스트리밍에서 수행되는 **각 연속적인 작업 단계**가
  - 이 작업을 수행할 수 있는 **익스큐터 수**에 대략 비례하는 **다수의 병렬 청크**로 분리된다는 아이디어
- **각 익스큐터**는 자체 작업 **청크**를 받아
  - 두번째 요소가 들어올 때까지 **별도로 작업**
- 특정 리소스는 **연산의 진행 상황**를 추적하는 임무를 수행
- **스파크 스트리밍**에서 이는 **드라이버**의 **동기화 포인트**로
  - 다음 단계로 작업을 진행할 수 있게 함
- 그러한 예정된 단계들 사이에서
  - 클러스터에 있는 모든 **익스큐터**는 같은 일을 함
- 이 **스케줄링 프로세스**에 전달되고 있는 것은
  - 사용자가 데이터에서 **실행하고자 하는 처리**를 설명하는 함수
- 데이터는 **이미 익스큐터**에 있으며
  - 클러스터의 수명 동안, 이러한 **리소스**들에게 직접 전달되는 경우가 대부분
- **함수 전달 방식**(function-passing style)
  - **상태 비동기식**으로 ㅈ분산된 **변하지 않는 불변의 데이터**에
    - **안전한 함수**를 전달하고
    - **느슨한 결합기**를 사용하여 중간 데이터 구조를 제거
- 좀 더 많은 데이터 처리가 **예악되는 빈도**는 **시간 간격**에 따라 결정 됨
- 이 **시간 간격**은 배치 처리 시간으로 측정되는 임의의 기간,
  - 클러스터에서 **벽시계**(wall clock) 시간 관측치로 예상되는 시간 간격
- 스트림 처리를 위해
  - 데이터 처리의 **실시간 개념**을 더 잘 근사화하는 **작은 고정 간격**으로 장벽을 구현

#### 대량 동기화 병렬 처리
- **BSP**는 병렬 처리를 위한 매우 일반적인 모델
- 세가지 핵심 개념
  - 각 프로세싱과 메모리 기능을 수행하는 다양한 구성 요소
  - 구성 요소 사이에 일대일 방식으로 메세지를 전달하는 라우터
  - 정규 시간 간격 `L`에서 구성 요소의 전체 또는 부분 집합을 동기화 하는 기능
    - `L : 주기성 파라미터`
- **대량 동기화 모델**의 목적은
  - 각 에이전트에 의해 연산이 수행될 수 있는 순간을 생각하도록 하는
  - 명확한 정의를 제공하는 동시에
    - 정기적으로 지식을 **통합**하여 하나의 **집계 결과**를 얻는 것
- 발리안트가 말한 개념
  ```md
  - 연산은 일련의 **슈퍼스텝**(프로세서에 의해 처리되는 작업)으로 이루어짐
  - 각각의 **슈퍼스텝**에서
    - 각 구성요소는
      - **로컬 연산 단계**
      - **메세지 전송**
      - **다른 구성요소로부터의 (명시적인) 메세지 도착의 조합**으로 구성된 작업을 할당 받음
  - `L`시간 단위의 각 기간이 끝나면
    - 모든 구성 요소에 의해 **슈퍼스텝**이 완료되었는지 여부를 결정하기 위해
    - **전역적인 점검**이 이루어짐
  - 만약 그렇다면, 그 머신은 **다음 슈퍼스텝**을 진행
  - 그렇지 않다면, 다음 기간의 `L`단위는, **미완성된 슈퍼스텝**에 할당
  ```
- 이 모델은
  - 이 연산 모드의 **확장성**과 **비용**에 대한 보증을 제공
- 이는 구글의 프라겔과 같은 **현대적인 그래프 처리 시스템**의 설계에 영향을 줌
- 여기서는 `spark`의 `Dstream`에서
  - **병렬 연산의 동기화**를 말하기 위한 방법으로 사용됨

### 5.5.2. 한번에 한 레코드 처리
- 대표적으로 **파이프라이닝**(pipelining)에 의한 **한 번에 한 레코드 처리 함수**가 있음
- 사용자 지정함수에 의해 설명된 대로
  - **전체 연산을 분석**하고
  - **클러스터의 리소스**를 이용하여, 파이프라인으로 전개
- 이후 규정된 **파이프라인**을 따라 다양한 리소스를 통해 **데이터를 전송**
- 연산의 각 단계는, 특정 지점의 **클러스터 내 특정 위치에서 구체화**되는 점에 유의
- 위 패러다임에 의해 `apache flink`, `Naiad`, `Storm`, `IBM Stream`등이 있음
- 이는 그 시스템이 반드시 **마이크로배칭**을 할 수 없다는 것을 의미하는 것은 아니지만,
  - 오히려 그들의 **주요 방식**
  - 또는 가장 **기본적인 작동방식**을 특징 짓고,
    - 종종 그것의 처리 핵심에 있는 **파이프라인 프로세스**에 대한 의존성에 대해 진술
- **시스템**이 **특정 이벤트**의 도착에 반응하는데
  - 필요한 **최소 지연 시간**과 **필요 시간**은 서로 매우 다름
- **마이크로 배칭** 시스템의 **최소 지연 시간**은
  - 현재 **마이크로배치**의 수신을 완료하는데 필요한 시간과
  - 이 데이터가 속하는 **익스큐터**에서 작업을 시작하는데 필요한 시간(**예약 시간**)임
- 한편 레코드를 **하나씩 처리하는 시스템**에서는
  - 관심의 대상이 되는 사건을 충족시키는 **즉시 반응**할 수 있음

### 5.5.3. 마이크로배칭과 한 번에 하나 : 트레이드 오프
- `더 높은 대기시간`에도 불구, **마이크로배칭** 시스템은 다음과 같은 이점 제공
  - 동기화 장벽 경계에서 **적응**할 수 있음
    - 다수의 익스큐터가 불충분하거나, 데이터가 손실되는 것으로 나타난 경우
      - 이러한 **적응**은, 오류로부터 복구해야하는 **과제**를 나타낼 수 있음
    - **주기적인 동기화**는 익스큐터 노드를 추가하거나, 제거할 수 있는 기회를 줄 수 있으며
    - **데이터 소스의 처리량**을 통해 관찰되는 **클러스터 로드**에 따라
      - 리소스를 늘리거나, 축소할 수 있는 가능성 제공
  - **BSP 시스템**은 특정 데이터 배치의 **시작과 끝**을 나타내는 배치 결정이, **결정론적**이고 기록되기 때문에,
    - 때때로 **강력한 일관성**을 제공하는데 많은 시간 할애 가능
    - 어떤 종류의 연산이든 **다시 할 수 있으며, 두번째에 같은 결과를 낼 수 있음**
  - 마이크로배치를 시작할 때, 탐색하거나 검사할 수 있는 **사용 가능한 데이터셋**을 확보하면
    - 데이터를 연산하는 방법에 대한 **아이디어**를 제공할 수 있는 **효율적인 최적화**를 수행할 수 있음
    - 각각의 **마이크로 배치**에서 그것을 이용하여
      - 가능한 모든 입력에 사용되는 **일반적인 처리** 보다는 구체적인 **사례**를 고려할 수 있음
    - 예시로,
      - **각각의 마이크로 배치**를 처리하거나, 떨어뜨리기로 결정하기 전에
      - **샘플**을 확보하거나, 통계적 조치를 연산할 수 있음

## 5.6. 마이크로배치와 한 번에 한 레코드 처리 방식을 더욱 가깝게 만들기
- `Apache Flink` 또는 `Naiad` 같은 시스템에서 구현되는 **마이크로배치**와
  - **한 번에 한 레코드씩 처리**하는 방식의 결합은 여전히 연구 대상
- 모든 문제를 해결하지는 못하지만
  - **마이크로배칭**에 의존하는 기본 구현으로 뒷받침되는 **구조적 스트리밍**은
  - `API` 수준에서 해당 선택을 **공개**하지 않으므로,
    - **고정 배치 간격**과 무관하게 진화할 수 있음
  - 실제로 **구조적 스트리밍**의 기본 내부 실행 모델은
    - **동적 배치 간격**을 사용한 **마이크로 배치** 모델
  - 구조적 스트리밍은 또한 일부 **운영자**를 위해 **지속적인 처리**를 구현

## 5.7. 동적 배치 간격
- **동적 배치 간격**(dynamic batch interval)
- **동적 배치 간격**은 스트리밍 데이터 프레임 또는 데이터셋의 **데이터 재연산**이
  - 네트워크를 통해서 보이는 **새로운 요소**와 함께
  - 기존 **데이터의 업데이트**로 구성된다는 개념
- 이 **업데이트**는 **트리거**에 기초하여 실행되며,
  - 업데이트의 일반적인 기준은 **지속 시간**이 됨
- 이 지속 시간은 여전히
  - 전체 클러스터 내에서 **동기화 될 것으로 예상**하고
  - 모든 **익스큐터가 공유**하는 시간의 **단일 동기 소스**를 나타내는
    - 고정된 **세계 시간 신호**에 기초하여 결정됨
- 그러나 이 **트리거**는 또한 `가능한 한 자주`에 대한 설명이 될 수 있음
- 그 설명은 단순히 `첫 번째 배치의 합리적인 초기 시간`을 고려할 때
  - `이전 배치가 완료되는 즉시` 새로운 배치를 시작해야 한다는 생각일 뿐임
  - 이는 시스템이 가능한 한 **자주 배치**를 시작한다는 것을 의미
- 이 상황에서 관찰할 수 있는 **지연 시간**은 **한 번에 한 요소**에 가까움
- 이 시스템에 의해 생산된 **마이크로 배치**가
  - **관리 가능한** 가장 작은 단위로 수렴되어
  - 결과를 산출하는 데 필요한 **익스큐터 연산**을 통해
    - 우리 스트림이 더 빨리 흐르게 된다는 것을 의미
- 그 결과가 나오는 대로
  - **스파크 드라이버**에 의해 **새로운 쿼리**가 시작되고 **스케줄링** 될 것

## 5.8. 구조적 스트리밍 처리 모델
- 구조적 스트리밍 처리의 주요 단계
  - 스파크 드라이버가 새 배치를 트리거 하면,
    - 특히 데이터 소스에서 읽은 **데이터 계정**을 업데이트 하는 것으로 시작하는데,
    - 특히 최신 배치의 **시작과 끝에 대한 데이터 오프셋**을 가져옴
  - 논리적 계획, 데이터에서 실행할 **연속 단계 구성**, **쿼리 계획**(단계적 최적화)가 이루어짐
  - 새로 고치려는 **연속 쿼리**를 업데이트 하기 위해
    - **새로운 데이터 배치**를 추가하여 
    - **실제 연산**을 시작하고 예약
- **연산 모델**의 관점에서 `API`가 **스파크 스트리밍**과 크게 다르지 않음

### 5.8.1. 배치 간격의 소멸
- 구조적 스트리밍 배치의 **의미**와 운영과 관련된 **영향**
- 구조적 스트리밍에서 사용하고 있는 **배치 간격**은 더 이상 `연산 비용이 아님`
  - 스파크 스트리밍을 사용하면 `2분 마다 데이터 생산, 2분마다 스파크 메모리로 데이터 전송`
    - 이후 마이크로 배치를 위한 클러스터 메모리를 삭제하기 위해
    - `2분 안에 데이터 배치에 대한 연산 결과 생산 필요`
  - 이상적으로는 **유입되는 만큼** 많은 데이터가 흘러나오고,
    - 클러스터의 **집단 메모리 사용**은 안정성을 유지함
- 구조적 스트리밍에서 **고정된 시간 동기화**가 없으면, 클러스터에서 **성능 문제**를 볼 수 있는 기능이 더욱 복잡해짐
  - 새로운 데이터가 **유입되는 속도**만큼 **빠른 속도로 데이터를 계산**하여
    - 데이터를 **삭제 할 수 없는 클러스터**는 지속적으로 증가하는 **배치 처리 시간**을 볼 수 있고,
    - 데이터 성장속도는 **가속화**
  - 이 배치 처리 시간을 **유지**하는 것이 핵심이 될 것이라 기대할 수 있음
- 그러나 데이터 **처리량**과 관련하여, 올바른 크기의 **클러스터**가 있다면
  - 가능한 **자주 업데이트**되는 많은 장점이 있음
- 특히 **보수적인 배치 간격**의 시간에
  - 우리가 사용했던 것보다 더 높은 **세분성**을 가진 **구조적 스트리밍 클러스터**로부터 
  - **매우 상세한 결과**를 볼 수 있을 것으로 예상해야함