# [CHAP.06] 스파크의 복원력 모델
- 대부분의 스트리밍 job은 길게 실행 됨
- 처리된 데이터의 스트림은
  - 시간이 지남에 따라 **지속적으로 실행되는 잡**으로 이어짐
- 데이터를 처리할 때 데이터가 처리 시스템을 떠난 후
  - **재생산하기 어려운** 중간 결과를 축적할 수 있음
- 실패 비용은 상당하며, 경우에 따라 완전한 회복이 어려운 경우도 존재
- 분산 시스템, 특히 일반 하드웨에 의존하는 시스템에서는
  - **실패가 크기의 함수**
- apache spark platform이 제공하는 **복원력**
  - 부분적 **실패**를 어떻게 복구할 수 있는지
  - 장애가 발생했을 때, 시스템을 통과하는 데이터에 대해 **어떤 종류의 보장**을 받을 수 있는지

## 6.1. 스파크의 탄력적인 분산 데이터셋
- 스파크는 **탄력적 분산 데이터셋**(RDD; Resilient Distributed DataSet)에 데이터 표현을 구축
- 이를 통해 스파크의 **내결함성**을 보장
- RDD는 **개별 노드**에 저장되고
  - 사용자에게 **위치 투명 데이터 구조**로 제공
  - **스파크 드라이버**에 의해 추적되는 
  - **데이터 세그먼트**인 **파티션**으로 구성
- **블록**은 분산 파일 시스템에 저장된 **데이터 요소**
- 데이터는 **파티션**으로 저장하며
  - 파일 내부에 색상으로 표시된 **블록의 열**로 표현
- 각 파티션은 **executor**에 의해 읽히며, 파티션은 **수평 블록**으로 간주
- 실제 데이터 처리는 **executor**내에서 이루어짐
- `DataFrame/DataSet`, `DStream`을 포함한 모든 추상화 및 배치 스트리밍은
  - `RDD`에 의해 생성된 기능을 사용하여 구축되며,
  - 동일한 **내결함성** 기능을 상속
- `RDD`는 **필요한 기간 동안 데이터를 메모리에 저장**하며
  - 시스템에 **충분한 용량**을 제공하도록 노력함
  - `Storage Level`을 통해 구성 가능하며
    - **캐싱 작업**을 호출하여 명시적으로 제어 가능
- `spark`가 **데이터 수정**을 통해 **사용자 연산**의 진행 상황을 추적
- `WordCount` 예시
  ```scala
  val file = spark.textFile("hdfs://...")
  val wordsRDD = file.flatMap(line => line.split(" ")).map(word => (word, 1)).reduceByKey(_ + _)
  val scoredRDD = words.map{ case (k,v) => (v,k)}
  ```
  - RDD 운영 체인(DAG)
    ```bash
    MappedRDD  # scoreRDD
    -> MapPartitionsRDD # wordsRDD
    -> ShuffleRDD 
    -> MapPartitionsRDD 
    -> MappedRDD 
    -> FlatMappedRDD 
    -> MappedRDD 
    -> HadoopRDD
    ```
- `DAG`는 **내부 데이터**와 **의존성**을 나타내기 때문에
  - `DAGScheduler`라는 적합한 명칭의 스케줄러에 **연산 분배 방법**을 알려주고
  - **실패 복구 기능**의 기초
- 시스템은 이러한 `분산 데이터 수집의 순서 생성`을 **추적**할 때
  - **수행한** 작업과 **수행해야할** 작업을 추적

## 6.2. 스파크 컴포넌트
#### 사용자 컴포넌트
- 스파크 스트리밍의 어플리케이션은 `action` 및 `transformation`으로
  - 분류된 **복원력 있는 데이터 구조**(RDD, DStream, Streaming DataSet)에서 작동하는
  - **사용자 지정 함수 호출**로 구성

#### 변형된 사용자 프로그램
- 사용자 프로그램은 지정된 호출 중 일부를 수정하여
  - 가장 간단하고 접근하기 쉽고 이해하기 쉬운
  - **맵 퓨전**을 만들기 위해 **조정 작업**을 수행할 수 있음

#### RDD
- 분산되고 복원력 있는 **데이터셋**의 논리적 표현
- 파티션의 집합

#### 파티션
- 독립적으로 로드할 수 있는 데이터셋의 **물리적인 세크먼트**

#### 스테이지
- 사용자 **작업**은 여러 **스테이지**로 그룹화하며
- 그 경계는 **사용자 작업**을 **개별적으로 실행**해야 하는 단계로 구성
- 두 별개의 `upstream`작업 결과 사이의 **결합**과
  - 같이 여러 노드에서 **데이터 셔플**이 필요한 작업은
  - 별개의 **스테이지**를 표시함
- 스테이지는 **sequencin**의 단위
- 이는 **차례대로** 실행되며, 주어진 시간에 **상호 의존적인** 스테이지 중 최대 **하나**를 실행할 수 있음

#### 잡
- **스테이지**가 정의되면, 스파크가 수행해야 하는 내부 **작업**은 명확
- 스테이지에서 일련의 상호 **의존적인 job**이 정의
- job은 정확히는 **스케쥴링 단어의 용어**
- 큐에서 대기 중이거나, 현재 여러 시스템에서 실행 중인지 여부에 관계 없이
  - 전체 **스파크 클러스터**의 관점에서
  - 현재 **진행 중인 작업**을 설명

#### 태스크
- **소스 데이터**가 클러스터에 있는 **위치**에 따라
  - 분산/단일 머신 컴퓨팅 사이의 개념적 경계를 넘어 **task** 단위로 분할 가능
- **task**는 **로컬 연산 단위**로
  - job의 local executor의 경계 부분 이름

### 정리
- spark는 이러한 단계들이 해를 입지 않도록 보호하고
- 이 프로세스의 어떤 스테이지에서는
  - **사고**가 발생할 경우, 신속하게 **복구**하는 것을 목표로 함
- 위에서 언급한 개념, 태스크, 잡, 스테이지 또는 프로그램 수준에서 발생하는
  - **재시작** 및 **체크포인팅 작업**으로 구성 된
  - **내결함성 설비**에 반영

## 6.3. 스파크의 내결함성 보장
- 스파크의 **내결함성 보장**을 **폭발 반경 증가**(increasing blast radius)
- **완만한 실패**부터 **더 큰 실패**에 이르기까지 **체계적**으로 볼 수 있음

### 6.3.1. 태스크 실패 복구
- 실행중인 인프라에 `OOM`, `Network`, `Storage` 또는 처리중인 데이터 품질에 관련된 문제(parsing, NFE, NPE 등)
  - 태스크 실패 가능
- 태스크의 입력 데이터가 `cache()`, `persist()` 호출을 통해 저장되었고
  - 선택한 스토리지 레벨이 **복제**(`_2`로 끝나는 스토리지 레벨, `MEMORY_ONITY_SER_2` 등)를 의미한다면
  - 해당 태스크의 **복사본**은 클러스터 다른 시스템에 **완전한 형태**로 존재
    - 입력 내용의 **재연산 필요 x**
  - 그런 다음 그 입력을 사용하여 **태스크 재시작 가능**
- 지속성이 없거나 스토리지 레벨이 **태스크 입력 데이터 복제본의 존재를 보장하지 않음**일 경우
  - 스파크 드라이버는 사용자 지정 연산을 저장하는 `DAG`를 참조하여
  - job의 어떤 segment를 **재연산할지 판별**
- 결과적으로 **캐싱** 또는 **스토리지** 레벨에 저장하기에 충분한 예방조치가 없으면,
  - **태스크 시패**로 인해 **스테이지 경계**까지 다른 **재연산**이 유발될 수 있음
- **스테이지 경계**는 **셔플**을 의미
  - 셔플은 `중간 데이터`가 어떻게든 **구체화**됨을 의미
- 셔플은 `executor`를 데이터 서버로 변환하여
  - 대상으로 사용되는 다른 `executor`에 데이터 제공 가능
- `executor`에는 **셔플**을 유발한 **맵 작업의 복제본**이 존재
- 셔플에 참여한 `executor`는 그 결과로 **이어진 맵 작업의 복제본**을 가짐
- 그러나 죽어가는 downstream executor를 가지고 있고,
  - 셔플의 **upstream server**(맵과 같은 출력 제공)에 의존할 수 있다면, 희망 존재
- 만약 upstream executor 중 하나가 손상된 상황이 발생했다면?

### 6.3.2. 스테이지 실패 복구
- **태스크 실패**(executor 손상)가 클러스터에서 가장 빈번히 발생하는 사건
  - 완화해야할 가장 중요한 이벤트
- **반복적인 태스크 실패**는 해당 태스크가 포함된 **스테이지 실패**로 이어짐
- 임의의 스테이지 실패에 저항할 수 있는 두번째 기능인 **셔플 서비스**(shuffle service)가 제공됨
- 이 실패가 발생하면
  - 항상 데이터의 **일부 롤백**을 의미
  - 정의에 따라 셔플 작업은 앞선 단계와 관련된 **모든 이전 executor**에 따라 다름
- `spark 1.3`부터 **셔플 서비스**를 제공
- 셔플 서비스를 사용하면
  - **좋은 지역성**을 지닌 클러스터를 통해
    - **저장/분산된 맵 데이터**에 대해 작업할 수 있게 해줌
  - 스파크 태스크가 아닌 **서버**를 통해 제공
    - 이는 스파크에 **의존하지 않고**, **executor**보다 오래 실행되는 서비스
    - java로 작성된 **외부 파일 교환 서비스**
    - spark의 모든 클러스터 모드에서 **별도의 프로세스로 연결**되며
      - 단순히 셔플 직전에 **executor**가 데이터를 **안정적으로 전송**할 수 있도록 **데이터 파일 교환 허용
    - `netty backend`를 사용하여
      - 데이터를 전송할 때 **매우 낮은 오버헤드**를 허용하도록 최적화
    - 이런 방식으로 셔플 서비스에 **데이터 복제본**이 있는 즉시 **맵 태스크**실행 후 **executor**가 종료될 수 있음
    - 데이터 전송이 더 빠르기 때문에 **전송 시간 단축**
      - executor가 문제에 직면할 수 있는 **취약한 시간**을 줄이게 됨

### 6.3.3. 드라이버 실패 복구
- 스파크 드라이버의 역할은 필수적
- **블록 매니저**의 보관소는
  - 각 데이터 블록이 클러스터에서 상주하는 위치를 알고 있는데,
  - 이는 또한 `DAG`가 위치하는 곳
- `job, metatdata` 그리고 `log`의 **스케줄링 상태**가 위치
- 드라이버가 손실되면, **스파크 클러스터 전체**가 연산의 어느 단계에 도달했는지,
  - 연산이 실제로 **무엇으로 구성되어 있는지**
  - 데이터를 어디서 찾아야 하는지 잃어버릴 수 있음

#### 클러스터 모드 배포
- cluster deployment mode를 구현하여
  - 드라이버 프로그램을 사용자 컴퓨터가 아닌, **클러스터에서 호스트**
- **client mode**
  - 드라이버가 **어플리케이션을 제출하는 client**와 동일한 **프로세스**에서 시작
- **cluster mode**
  - 드라이버가 클러스터 **내부의 작업자 프로세스** 중 하나에서 시작되고
  - client process는 application이 완료될때까지 기다리지 않고,
    - 어플리케이션을 제출해야하는 책임이 있는 즉시 종료
- spark가 **자동 드라이버 재시작**을 수행할 수 있게 하여
- `fire and forget`으로 job을 시작
- 스파크의 모든 **클러스터 모드**는
  - 사용자가 app log에 액세스 할 수 있는 **web UI** 제공
- driver process가 **클러스터 매니저**에 의해 다시 시작되기 때문에
  - 드라이버의 실패가 **작업의 끝을 의미하지는 않음**
- 그러나 이전의 **드라이버 시스템**에 저장된 연산의 **임시적인 상태**가 손실될 수 있기 때문에
  - 처음부터 복구할 수 있음

#### 체크포인팅
- 드라이버 손상시 **중간 상태가 손실되지 않도록** 제공하는 기능
- 어플리케이션 상태의 **스냅샷**을 **디스크에 주기적으로 기록**
- `sparkContext.setCheckpointDirectory()` 옵션은
  - 드라이버가 **로컬 파일 시스템**에서 중간 `RDD`상태를 재구성하려고 시도하기 때문에
  - **신뢰할 수 있는 스토리지**(e.g. HDFS)를 가리켜야 함
  - 클러스터 `executor`에서 생성되므로, 이를 백업하기 위해 **드라이버와 상호작용은 x**
- 스파크 클러스터에는 여전히 **잠재적인 실패**를 해결하지 못한 구성 요소인
  - **마스터 노드**가 남아 있음

## 6.4. 요약
- 위의 모든 내용은 **장기 실행**, **내결함성** 및 **성능이 뛰어난 어플리케이션**을
  - 제공해야 한다는 점에서 `streaming api`에 적용
- 이는 **클러스터 결함 빈도**에 대한 다양한 우려를 반영
  - `zookeeper`를 통해 최신 상태로 유지되는 **장애 조치 마스터 노드 설정**과 같은 기능은
    - **스파크 어플리케이션 설계**에서 **SPoF**를 방지하는 것
  - 스파크 **셔플 서비스**는
    - 결함이 있는 `executor`를 통해
    - 전체를 취약하게 만드는 연산 단계의 긴 목록의 끝에
    - **셔플 단계와 관련된 문제를 방지**하기 위해 제공
- 위 두가지 문제중 후자는 더 자주 발생
  - 첫 번째는 **가능한 모든 조건**을 다루는 것이고
  - 두 번째는 부드러운 **성능**과 **효율적인 복구**를 보장