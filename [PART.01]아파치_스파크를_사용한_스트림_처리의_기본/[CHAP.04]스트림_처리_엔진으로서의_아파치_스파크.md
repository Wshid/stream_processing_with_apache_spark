# [CHAP.04] 스트림 처리 엔진으로서의 아파치 스파크
## 4.1. 두 API 이야기
- 스파크 스트리밍
  - 마이크로배치 형태로 수행
- 구조적 스트리밍
  - SQL 쿼리 최적화 장치인 `Catalyst`에 구축된 API와 커넥터 집합
  - DF에 기반한 API와 스트림으로부터 발생하는 **새로운 레코드**로
    - 끊임없이 업데이트되는 무한한 테이블에 대한 **연속적인 쿼리 개념**을 제공
- 맵리듀스 이전모델과 비교하여
  - 스파크는 프로그래머가 **머신러닝**이나 **이벤트 시간 조작**을 포함한
  - 복잡한 처리를 표현할 수 있는 **풍부한 연산자 셋**을 제공
- 스파크는 **프로토타이핑 제작**의 장으로 활용할 수 있는
  - `scala REFL`(Read-Eval-Print-Loop)를 제공함
  - 내장 shell
- zeppelin, jupyter와 같은 노트북 구현이 있으며,
  - 대화형 경험을 웹 인터페이스로 제공

## 4.2. 스파크의 메모리 사용
- 스파크는 **데이터 소스**에서 초기에 로드해야하는 **데이터셋의 슬라이스**에 대한
  - **인메모리 스토리지**를 제공
- 데이터 원본은 **분산 파일 시스템** 또는 다른 **저장 매체**를 의미
- 스파크의 인메모리 스토리지 형태는 **데이터를 캐싱하는 작업**과 유사
- 인메모리 스토리지의 `value`는
  - 초기 데이터 소스인 `base`와 그게 적용되는 **연속적인 운영계층**을 가지고 있음

### 4.2.1. 실패 복구
- 스파크는
  - 어떤 데이터 소스를 사용하여 데이터를 **수집**했는지 정확히 알 고 있으며,
  - 지금까지 수행된 작업도 **모두 알고 있기 때문에**
  - 손상된 excutor에 있던 **손실된 데이터**의 세그먼트까지 처음부터 구성 가능
- **재구성**(recoverry)는 완전히 **처음부터**시작할 필요가 없다면 더욱 빨리 진행됨
- 분산 파일 시스템과 유사한 방식으로 **복제 매커니즘** 제공
- 하지만 메모리는 한정된 상품이기 때문에
  - 스파크는 기본적으로 **캐시의 수명을 짧게 만듦**

### 4.2.2. 지연 평가
- 스파크가 하는 작업중 상당 부분은 **지연**
- 프로그램이 일련의 **선형 연산**으로 구성되어 있고
  - 이전 작업이 **다음 작업**으로 유입되면
  - 다음 단계가 입력값을 소비한 직후에는
  - **중간 결과가 사라짐**

### 4.2.3. 캐시 힌트
- 중간 결과에 대해 **여러번의 작업을 수행하게 될 경우**
  - 여러번 계산해야 할까?
- 중간값이 중요하고, 그 콘텐츠가 나중에 어떻게 보호되어야 하는지
  - **사용자가 명시할 수 있음**
- 스파크는 클러스터의 **메모리 부족**일 경우,
  - 캐시를 **2차 스토리지**에 흘릴 수 있는 기회 제공
- **인메모리 작업**을 **2차 스토리지**로 확장하고
  - 임시 **최대 부하**에 직명했을 때
  - 데이터 프로세스의 기능적 측면을 보존할 수 있도록
    - **훨씬 느린 스토리지**로 확장

## 4.3. 지연 시간에 대한 이해
- 스파크 스트리밍은 **마이크로 배칭**을 선택할 수 있음
  - 일정한 간격으로 `chunk`를 생성하고,
  - 그 간격인 `tick`이 경과되면,
  - 마지막 간격에 걸쳐 수집된 데이터를 **처리**하기 시작
- 구조적 스트리밍은
  - 문제의 간격을 가능한 **작게**(마지막 마이크로배치의 처리 시간) 만들 것이라는 점에서 **다름**
  - 어떤 경우에는 **연속 처리 모드**를 제안
- 오늘날 **마이크로배칭**은
  - 아파치 스파크에서 여전히 **스트림 처리**의 지배적인 내부 실행 모드
- **마이크로 배칭**의 결과는
  - 마이크로배치가 **배치 간격의 최소 시간만큼**
  - 배치의 특정 요소의 처리를 지연시키는 것
- 스파크는 작동하기 전에 하나의 배치로 최대한 모든 데이터 요소를 **지연**
- 다른 스트리밍 엔진은, 우선순위가 있는 일부 요소를 **빠르게 추적할 수 있게 함**
  - 이러한 요소들에 대한 빠른 대응성을 보장
- 위 특성 요소에 대해 **응답 시간**이 필수적이라면
  - **Apache Flink**나 **Apache Storm**과 같은 **대체 스트림 프로세서**가 더 적합
- 그러나 시스템을 모니터링할 때와 같이 **평균적으로** 빠른 처리를 하는데만 관심이 있다면
  - **스파크**는 좋은 선택
## 4.4. 처리량 지향 처리
- 스트림 처리에서 뛰어난 점
  - 처리량 지향의 데이터 분석
- 택시나 자동차를 타면 기차보다 빠르게 도착을 할 수 있으나,
  - 기차의 경우, 더 많은 승객을 도착하도록 보장함
- **기차**는 일부 승객이 출발할 때까지 기다려야 하는 비용으로
  - 동일한 궤도에 대해 더 높은 처리량을 보장
- 스파크 코어 엔진은 **분산 배치 처리**에 최적화
  - 시간 단위당 대량의 데이터를 처리할 수 있도록 보장
- 스파크는 **한 번에 많은 요소**를 처리하도록 하여 **분산 작업 스케줄링**의 오버헤드를 상쇄하며,
  - 이 장 앞부분에서 보았듯이 **인메모리 기법, 쿼리 최적화, 캐싱 및 코드 생성**까지 활용하여
  - 데이터 셋의 **변환 프로세스**를 가속화한다
- 스파크를 사용할 때 중요한 제약 조건
  - 처리된 데이터를 **수신하는 다운스트림 시스템**도 **스트리밍 프로세스**부터
  - 제공하는 전체 출력을 수용할 수 있어야 한다
  - 그렇지 않다면 갑작스런 **부하 피크**에 직면에 직면했을 때
    - 종속 장애를 일으킬 수 있는 **어플리케이션 병목 현상**을 발생시킬 위험이 있음

## 4.5. 스파크의 폴리글랏 API
- 스파크는 **스칼라 전용 프로젝트**로 처음 코딩
- `java, python, R` 언어를 사용해서 접속할 수 있는 **폴리글랏 프레임워크**가 됨
- 개발 언어는 여전히 스칼라

## 4.6. 데이터 분석의 빠른 구현
- 데이터 분석 파이프라인 개발시의 스파크 장점
  - 스칼라에서 간결하고 높은 수준의 API
  - 자바와 파이썬 호환되는 API를 제공하는 것 이상
- 개발 과정 전반에 걸쳐, 스파크의 **단순한 모델** 제공
- 머신러닝과 많은 분야를 위한 `java lib ecosystem`에 접근할 수 있음
  - `CoreNLP`를 사용하여 `tokenizer`를 사용 가능
- 전반적으로
  - **스트리밍 데이터 파이프 라인 솔루션**을 빠르게 프로토타입화 하여
  - 파이프라인 개발의 모든 단계에서, 적절한 구성요소 선택할 수 있을 만큼
    - 첫 번째 결과를 빠르게 얻음
- **내결함성 모델**의 이점을 제공
  - 결함이 있는 기계가, 스트리밍 어플리케이션을 중단하지 않을 것이라는 확신
  - spark job의 재시작을 보면
    - 무중단 스트리밍 시의 복원력이 높음을 느낄 수 있음
- 스파크는
  - **지연 시간**에서 `trade-off`를 이루면서도
  - 민첩성을 갖춘 데이터 분석 파이프라인을 구축하기 위해 **최적화 하는 프레임 워크**

## 4.7. 스파크에 대해 더 알아보기
- 러닝 스파크
- 스파크 완벽 가이드
- 공식 문서

## 4.8 요약
- 주요 성능 향상, 인메모리 연산을 통해 어떻게 모델 확장하는지
- 새로운 고차 기능을 갖춘 API
- 하둡에 비해 **더 작은 공간에 초점**
- 스트리밍 API, 마이크로 배칭 접근법의 의미, 어떤 용도에 적합한지
- 스트림 처리 고려
- 안정적이고 내결함성 있는 배포와 함께
  - 민첩성을 갖춘 파이프라인을 구축하는 것 -> 최선의 사용 사례