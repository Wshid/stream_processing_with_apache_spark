## [CHAP.02] 스트림 처리 모델
- 스트림 처리의 구성 요소
  - 데이터 소스
  - 스트림 처리 파이프라인
  - 데이터 싱크
- 과거 계산 기록 : bookeeping
  - 상태 기반 스트림 처리 특성화
- 문제 해결
  - **이벤트 도착 순서**와 **적시성**이 일치하지 않으면 어떻게 할 것 인가
  - 타임스탬프 이벤트 스트림과 기본 개념

## 2.1. 소스와 싱크
- 두가지 스트리밍 시스템
  - 구조적 스트리밍
  - 스파크 스트리밍
- 프로그램의 Runtime에 입력된 데이터에 대해서만 작동 가능
  - **다른 시스템으로 전송되는 즉시**, 데이터에 대한 작동 중지
- 데이터 소스
  - 아파치 스파크의 **스트리밍 프레임워크**에서 데이터 스트림 접근 가능
  - 스트림 처리의 맥락에서
    - 스트림으로부터 데이터에 접근하는 것을 **스트림 소비**(consuming the stream)라고 함
  - 이 추상화는 `kafka`, `flume`, `twitter`, `tcp socket`등과 같은
    - 특정 시스템에 연결하려는 **인스턴스의 구현**을 허용하는 인터페이스로 제공
- streaming sink
  - `spark`외부에 데이터 스트림을 쓰는데 사용
- 스트림 처리 시스템 구성
  - `source - process - sink`
- `source`와 `sink`는 **시스템의 경계**를 나타냄
  - 분산 프레임 워크가 컴퓨팅 리소스간에 매우 복잡한 footprinting을 가질 수 있음
    - 예시 : spark가 다른 `spark cluster` 혹은 `kafka`가 사용되는 다른 분산 시스템에 연결 할 수 있음
- 하나의 `sink`는 다운 스트림 프레임워크의 `source`
  - 일반적으로 이 구성을 `pipeline`이라고 함

## 2.2. 서로 정의된 불변의 스트림
- spark의 두 스트림 API는 **FP**의 형식을 따름
- `data stream`에서 작동하는 **변환/집계**는
  - 해당 스트림이 **변경 불가능**하다고 가정하여 선언
- 따라서 **하나의 주어진 스트림에 대해 하나 또는 여러 개의 요소를 변형하는 것은 불가능**
- 대신, 파싱된 데이터 스트림을 얻기 위해
  - 한 스트림의 콘텐츠를 처리하는 방법을 표현하기 위한 **변환**을 사용
- 이는 프로그램의 어느 특정 지점에서도 프로그램에서
  - **명시적**으로 선언한 일련의 **변환** 및 **조작**을 통해
  - 모든 데이터 스트림을 그것의 **입력**으로 추적할 수 있게 함
- spark cluster의 특정 프로세스는
  - **프로그램**과 **입력 데이터**만 사용하여
  - 데이터 스트림의 내용을 **째구성**할 수 있어 계산이 명확, 재현 가능

## 2.3. 변환과 집계
- spark는 `translation`, `aggregation`을 광범위하게 사용
- **변환**은 스트림의 모든 요소에 대해
  - 동일한 방식으로 **자신을 표현하는 계산**을 의미
  - 예시
    - 입력 스트림의 모든 요소를 두 배로 만들어주는
    - **파생 스트림**을 생성하는 것은, **변환**에 해당
- **집계**는
  - 많은 요소와 **현재까지 관찰된 스트림의 모든 요소에 의존**하는 결과를 생성
  - 예시
    - 입력 스트림 중 상위 `5`개의 숫자를 수집
    - 매 10분마다 일부 판독값의 **평균**을 계산
- **변환**은 **좁은 종속성**
  - 출력의 한 요소를 생성하려면, **입력 요소중 하나만 필요한 특성**
- **집계**는 **넓은 종속성**
  - 출력의 한 요소를 생성하려면, **지금까지 발생한 입력 스트림의 많은 요소 관찰**
- 이를 통해 **고차 함수**를 사용하여
  - 결과를 생성하는 기본 함수 표현 가능
- `spark streaming`과 `structured streaming`은
  - 데이터 스트림을 나타내는 **고유한 방법**이 있지만
  - 작동하는 `API`는 본질적으로 비슷함
    - **불변 입력 스트림**에 적용되는 일련의 **변환**형태로 존재하며
    - 적정한 **스트림**또는 **출력 작업**으로 **출력 스트림 생성**

## 2.4. 윈도우 집계
- 여러 장소의 로그를 중앙 집중식으로
- 최근 일정 기간 동안 발생한 **이벤트의 속성**을 살펴보기
- 규칙적이고 **반복적**인 시간 집계의 어플리케이션 => **window**

### 2.4.1. 텀블링 윈도우
- 각 `x` 기간의 그룹화 함수
  - `시간당 최대 및 최소 주변 온도`
  - `15분당 총 에너지 소비량`
- 각 그룹이 **이전 그룹**을 따르고,
  - **겹치지 않는 고정된 기간**의 그룹을 `tumbling windows`라고 함 
- **각 기간별로 독립적**이어야 함

### 2.4.2. 슬라이딩 윈도우
- 집계 기간 자체보다 **더 높은 빈도**로 보고되는 일정 기간의 집계
- **윈도우 길이**와 **빈도의 집계**를 의미
- 시간 간격 `x`에서 `y`빈도로 보고한 **그룹화 함수**와 같이 판독
  - `마지막 날의 평균 주가는 시간단위로 보고되었다`
- **평균 함수**와 **슬라이딩 윈도우**의 조합은
  - 가장 널리 알려진 슬라이딩 윈도우의 형태
  - **이동 평균**(moving average)
- 윈도우 크기가 30s이고, 보고 빈도가 10s인 윈도우
  - 0s, 30s
  - 10s, 40s
  - 20s, 50s
  - ...
- 다른 요소를 그대로 유지하면서,
  - 최신 데이터를 추가
  - 만료된 요소를 제거

## 2.5. 비상태 및 상태 기반 처리
- 구조적 스트리밍은
  - 데이터 스트림을 각 **행**이 요소에 해당하는 **가상 레코드 테이블**로 간주하여 이 논리를 뒷받침함

## 2.6. 상태 기반 스트림
- 스트림을 경우에 따라
  - **요소** 또는 **요소 그룹**의 연속적이고 독립적인 처리에 중점
  - `이벤트 로그에서 오는 경고 메세지`와 같이
    - 휴리스틱 기반으로 일부 요소에서 작업하는 경우
- 완벽하게 유효하나, 스파크와 같은 **고급 분석 시스템**을 필요로 하지 않음
- 종종 컬렉션에서 **특잇값**을 탐지하거나,
  - 이벤트 데이터로부터 **최근의 집계 통계**를 계산하는 것과 같이
  - 전체 스트림에 의존하는 분석을 기반으로 하는 **새로운 요소**에 대한 실시간 반응에 관심

### 상태 크기 제한하기
- 입력 데이터 스트림 크기에 비례하는 양의 **내부 데이터**를 저장하는 것
  - 하지만 이는, 레코드마다 컴퓨팅 시간 사용 및 무한한 메모리 요구사항이 존재
  - 일반적인 실수
- 스트림 처리의 전제는
  - 입력 이벤트 수에 **제한**이 없으며
  - 분산된 스파크 클러스터에서 **사용 가능한 메모리**가 클 수 있지만, 항상 **제한**되어 있음
  - 중간 상태 표현은 **데이터가 관찰**되는 
    - **전역 데이터 스트림**과 관련된 요소들 상에서
    - 동작하는 연산을 표현하는데 유용할 수 있으나,
    - 다소 안전하지 않음
- **중간 데이터**를 보유하기로 선택한 경우
  - `주어진 시간에 저장할 수 있는 양 < 입력으로 발생할 수 있는 데이터양과 관계없이 사용한 메모리`보다
  - 특정 상한에 **엄격하게 제한**되어 있는지 확인해야 함

### 상태 기반 스트림 처리
- stateful stream processing
- 입력 데이터 스트림에서 관찰된 새로운 데이터 요소에서
  - 무언가를 연산하고, 이 연산을 수행하는 데 도움이 되는 **내부 데이터**를 고치는 것을 원칙으로 함
- `이상 탐지`를 시도하는 경우
  - 우리가 모든 새로운 스트림 요소로 **업데이트**하려는 내부 상태는 **머신러닝 모델**이 되지만
  - 수행하려는 계산은 **입력 요소**가 비정상으로 **분류**되어야 하는지 아닌지 말하기 위한 것
- 대량의 컴퓨팅 성능을 활용할 수 있고, 실시간 데이터에 반응하는 새롭고 흥미로운 방법